{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_modeling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nov05/DS-Unit-2-Sprint-4-Project/blob/master/notebooks/03_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CalFgqk2Ding",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# created by nov05 on 2019-08-04\n",
        "# Nov05/DS-Unit-2-Sprint-4-Project/\n",
        "# notebooks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R11BFsBd4cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEKrsTZJdSHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import category_encoders as ce\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, \\\n",
        "     mean_squared_error, mean_squared_log_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B6BKA2Ok-sZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmsle(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
        "  \n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhrMpFaAHDfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fcee8e45-1910-4446-e6dc-06259a7f4120"
      },
      "source": [
        "###############################################\n",
        "# Data Loading\n",
        "###############################################\n",
        "url_tasks = \"https://raw.githubusercontent.com/Derek-Jones/SiP_dataset/master/Sip-task-info.csv\"\n",
        "url_dates = \"https://raw.githubusercontent.com/Derek-Jones/SiP_dataset/master/est-act-dates.csv\"\n",
        "tasks  = pd.read_csv(url_tasks, encoding='iso-8859-1')\n",
        "dates  = pd.read_csv(url_dates, encoding='iso-8859-1')\n",
        "\n",
        "# merge two datasets\n",
        "# there are duplicate TaskNumbers in both datasets\n",
        "# there are duplicate rows in \"dates\" dataset\n",
        "alldata = tasks.merge(right=dates[-dates.duplicated()], on='TaskNumber', how='inner')\n",
        "\n",
        "###############################################\n",
        "# Data Wrangling\n",
        "###############################################\n",
        "breakdown = (alldata[['ProjectCode', 'ProjectBreakdownCode']]\n",
        "             .groupby('ProjectCode').nunique()\n",
        "             .drop('ProjectCode', axis=1)\n",
        "             .reset_index())\n",
        "\n",
        "def wrangler(X):\n",
        "## data type conversion  \n",
        "  X['EstimateOn'] = pd.to_datetime(X['EstimateOn'], format='%d-%b-%y')\n",
        "  X['StartedOn'] = pd.to_datetime(X['StartedOn'], format='%d-%b-%y')\n",
        "  X['CompletedOn'] = pd.to_datetime(X['CompletedOn'], format='%d-%b-%y')\n",
        "\n",
        "## feature engineering\n",
        "  X['hoursestimatelog'] = np.log1p(X['HoursEstimate'])\n",
        "  X['daysactual'] = (X['CompletedOn']-X['StartedOn']).dt.days.abs()\n",
        "  X['estimateonsameday'] = X['EstimateOn']==X['StartedOn']\n",
        "  ## pandas.DataFrame.merge() behaves awkwardly in a function\n",
        "  ## so I have to do it in this way\n",
        "  tmp = (X[['ProjectCode']]\n",
        "         .merge(right=breakdown, on='ProjectCode', how='left'))\n",
        "  X['breakdown'] = tmp['ProjectBreakdownCode']\n",
        "#   tmp = (X[['DeveloperID']].merge(right=performancelevel,\n",
        "#                                   on='DeveloperID', how='left'))\n",
        "#   X['performancelevel'] = tmp['performancelevel'].astype(int)\n",
        "\n",
        "## missing values\n",
        "  X.replace([np.inf, -np.inf, pd.NaT], np.nan, inplace=True)\n",
        "wrangler(alldata)\n",
        "# alldata.to_csv(\"alldata.csv\")\n",
        "\n",
        "hoursactual_log = np.log1p(alldata['HoursActual'])\n",
        "hoursestimate_log = np.log1p(alldata['HoursEstimate'])\n",
        "\n",
        "###############################################\n",
        "# feature selection\n",
        "###############################################\n",
        "target = 'HoursActual'\n",
        "features = alldata.columns.to_list()\n",
        "# remove the following features\n",
        "fs = [ target,\n",
        "      'TaskNumber', # Drop because our goal is to predict sales for unknown stores\n",
        "      'Summary', # test column\n",
        "      'RaisedByID', 'AssignedToID', 'AuthorisedByID', 'DeveloperID',\n",
        "      'StatusCode', # this is real-time information\n",
        "      'ProjectCode', 'ProjectBreakdownCode',\n",
        "      'DeveloperHoursActual', 'TaskPerformance', 'DeveloperPerformance', # highly correlated with 'HoursActual'\n",
        "      'EstimateOn', 'StartedOn', 'CompletedOn', # independent on dates\n",
        "      'daysactual', 'estimateonsameday',  \n",
        "#       'hoursestimatelog',\n",
        "      'HoursEstimate',\n",
        "     ]\n",
        "for f in fs:\n",
        "  features.remove(f)\n",
        "print(\"total features:\", len(features), features)\n",
        "\n",
        "###############################################\n",
        "# Data Splitting\n",
        "###############################################\n",
        "trainval, test = train_test_split(alldata, test_size=0.1)\n",
        "print(\"trainval size:\", trainval.shape, \"test size:\", test.shape)\n",
        "assert alldata.shape[0]==trainval.shape[0]+test.shape[0]\n",
        "\n",
        "X_trainval = trainval[features]\n",
        "y_trainval = trainval[target]\n",
        "y_trainval_log = np.log1p(y_trainval)\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "y_test_log = np.log1p(y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total features: 5 ['Priority', 'Category', 'SubCategory', 'hoursestimatelog', 'breakdown']\n",
            "trainval size: (11069, 24) test size: (1230, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ_inVDMG-fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "059373eb-43c5-4258-8097-e2d4d0714a7b"
      },
      "source": [
        "###############################################\n",
        "# feature categories\n",
        "###############################################\n",
        "numeric_features = X_trainval[features].select_dtypes(include=np.number).columns.to_list()\n",
        "categorical_features = X_trainval[features].select_dtypes(exclude=np.number).columns.to_list()\n",
        "print(len(numeric_features), 'numeric features:', numeric_features)\n",
        "print(len(categorical_features), 'categorical features:', categorical_features)\n",
        "\n",
        "# select low cardinality features for one-hot encoding\n",
        "# select high cardinality features for ordinal encoding\n",
        "highcardi_features, lowcardi_features = [], []\n",
        "for col in X_trainval[categorical_features]:\n",
        "  if len(X_trainval[col].value_counts()) >= 10:\n",
        "    highcardi_features.append(col)\n",
        "  elif len(X_trainval[col].value_counts()) >= 2:\n",
        "    lowcardi_features.append(col)  \n",
        "# print(len(numeric_features), 'numeric features:', numeric_features)\n",
        "print(len(highcardi_features), 'high cardinality features:', highcardi_features)\n",
        "print(len(lowcardi_features), 'low cardinality features:', lowcardi_features)\n",
        "\n",
        "###############################################\n",
        "# Pipeline preprocessor\n",
        "###############################################\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "onehot_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', ce.OneHotEncoder(drop_invariant=True, use_cat_names=True))]) \n",
        "ordinal_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('one', onehot_transformer, categorical_features)\n",
        "#         ('one', onehot_transformer, lowcardi_features), # categorical_features\n",
        "#         ('ord', ordinal_transformer, highcardi_features), # categorical_features\n",
        "    ])\n",
        "###############################################\n",
        "# Pipeline fitting\n",
        "###############################################\n",
        "random_state = 5\n",
        "n_jobs = -1\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('rf', RandomForestRegressor(\n",
        "                               n_estimators=29,\n",
        "                               max_depth=6,\n",
        "                               random_state=random_state, \n",
        "                               n_jobs=n_jobs)), \n",
        "                          ])    \n",
        "pipeline.fit(X_trainval, y_trainval_log);"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 numeric features: ['Priority', 'hoursestimatelog', 'breakdown']\n",
            "2 categorical features: ['Category', 'SubCategory']\n",
            "1 high cardinality features: ['SubCategory']\n",
            "1 low cardinality features: ['Category']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxHTUvIKg6Qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dbeae265-f2d3-4ff2-8bde-be59b42cfa72"
      },
      "source": [
        "pred_trainval = pipeline.predict(X_trainval)\n",
        "print(\"trainval data RMSE score: %.3f\" % rmse(y_trainval_log, pred_trainval))\n",
        "\n",
        "pred_test = pipeline.predict(X_test)\n",
        "print(\"test data RMSE score: %.3f\" % rmse(y_test_log, pred_test))\n",
        "\n",
        "X_all = X_trainval.append(X_test)\n",
        "y_all = list(y_trainval) + list(y_test)\n",
        "y_all_log = np.log1p(y_all)\n",
        "pred_all = pipeline.predict(X_all)\n",
        "print(\"all data RMSE score: %.3f\" % rmse(y_all_log, pred_all))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainval data RMSE score: 0.640\n",
            "test data RMSE score: 0.642\n",
            "all data RMSE score: 0.640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6q4DJqEIXVX",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/model_persistence.html  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JLNPGoOdFVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b0d0b67-1aec-4b9b-80c8-02d63f8a8136"
      },
      "source": [
        "###############################################\n",
        "# Save Pipeline\n",
        "###############################################\n",
        "from joblib import dump, load\n",
        "dump(pipeline, 'pipeline.joblib') "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6b1u7PXlh1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cab54756-1b4b-45b5-cd3a-96c418fe7d93"
      },
      "source": [
        "###############################################\n",
        "# Load Pipeline\n",
        "###############################################\n",
        "rf = load('pipeline.joblib') \n",
        "\n",
        "pred_trainval = rf.predict(X_trainval)\n",
        "print(\"trainval data RMSE score: %.3f\" % rmse(y_trainval_log, pred_trainval))\n",
        "\n",
        "pred_test = rf.predict(X_test)\n",
        "print(\"test data RMSE score: %.3f\" % rmse(y_test_log, pred_test))\n",
        "\n",
        "X_all = X_trainval.append(X_test)\n",
        "y_all = list(y_trainval) + list(y_test)\n",
        "y_all_log = np.log1p(y_all)\n",
        "pred_all = rf.predict(X_all)\n",
        "print(\"all data RMSE score: %.3f\" % rmse(y_all_log, pred_all))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainval data RMSE score: 0.640\n",
            "test data RMSE score: 0.642\n",
            "all data RMSE score: 0.640\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}